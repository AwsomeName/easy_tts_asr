这些模型接受了 680,000 小时的音频以及从互联网收集的相应文字记录的训练。该数据的 65%（或 438,000 小时）代表英语音频和匹配的英语成绩单，大约 18%（或 126,000 小时）代表非英语音频和英语成绩单，而最后 17%（或 117,000 小时）代表非英语音频和英语成绩单。英文音频和相应的文字记录。这些非英语数据代表 98 种不同的语言。

正如随附论文中所讨论的，我们发现给定语言的转录性能与我们在该语言中使用的训练数据量直接相关。

https://huggingface.co/blog/zh/fine-tune-whisper


这个finetune，是调试OpenAI的这个whisper
先下载数据集，git clone ， git lfs fetch， git lfs checkout
注意，原来数据集，只尝试下载，建议替换成本目录下的脚本，可以仅加载本地的数据集。


终于run起来了，如图。
由于我的算力有限，先不继续研究了

后续应该使用Q_LoRA训练——不过不一定。
总之这个工作一定是会有人做的，以后有时间有缘再研究吧。